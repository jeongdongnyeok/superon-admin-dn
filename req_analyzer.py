#!/usr/bin/env python3
"""
requirements.txt ìµœì í™” ë„êµ¬
ì‹¤ì œ importë˜ëŠ” íŒ¨í‚¤ì§€ë§Œ ì¶”ì¶œí•´ì„œ ìƒˆë¡œìš´ requirements.txt ìƒì„±
"""

import os
import re
import subprocess

def find_imports(directory):
    """ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  import ë¬¸ ì°¾ê¸°"""
    imports = set()
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                filepath = os.path.join(root, file)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # import íŒ¨í„´ ì°¾ê¸°
                    patterns = [
                        r'^import\s+(\w+)',  # import package
                        r'^from\s+(\w+)',   # from package import
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, content, re.MULTILINE)
                        for match in matches:
                            if not match.startswith('backend'):  # ë¡œì»¬ ëª¨ë“ˆ ì œì™¸
                                imports.add(match)
                except Exception as e:
                    print(f"Error reading {filepath}: {e}")
    
    return sorted(imports)

def get_package_mapping():
    """Python ëª¨ë“ˆëª…ì„ pip íŒ¨í‚¤ì§€ëª…ìœ¼ë¡œ ë§¤í•‘"""
    return {
        'fastapi': 'fastapi',
        'uvicorn': 'uvicorn',
        'langchain_core': 'langchain-core',
        'langchain_openai': 'langchain-openai', 
        'langchain_community': 'langchain-community',
        'langchain_text_splitters': 'langchain-text-splitters',
        'langchain_huggingface': 'langchain-huggingface',
        'supabase': 'supabase',
        'torch': 'torch',
        'transformers': 'transformers',
        'gradio': 'gradio',
        'pandas': 'pandas',
        'numpy': 'numpy',
        'requests': 'requests',
        'yaml': 'PyYAML',
        'sklearn': 'scikit-learn',
        'PIL': 'Pillow',
        'cv2': 'opencv-python',
        'httpx': 'httpx',
        'pydantic': 'pydantic',
        'sqlalchemy': 'SQLAlchemy',
        'aiofiles': 'aiofiles',
        'openai': 'openai',
        'tiktoken': 'tiktoken',
        'obs_websocket_py': 'obs-websocket-py',
        'sentence_transformers': 'sentence-transformers',
        'faiss': 'faiss-cpu',
    }

def get_builtin_modules():
    """Python ë‚´ì¥ ëª¨ë“ˆ ëª©ë¡"""
    return {
        '__future__', 'os', 'sys', 'json', 're', 'datetime', 'asyncio',
        'typing', 'logging', 'pathlib', 'functools', 'collections', 
        'itertools', 'time', 'random', 'math', 'io', 'subprocess',
        'threading', 'multiprocessing', 'socket', 'urllib', 'http',
        'email', 'html', 'xml', 'csv', 'configparser', 'argparse',
        'tempfile', 'shutil', 'glob', 'fnmatch', 'pickle', 'base64',
        'hashlib', 'hmac', 'secrets', 'uuid', 'queue', 'copy',
        'weakref', 'gc', 'inspect', 'dis', 'traceback', 'warnings'
    }

def analyze_requirements():
    """í˜„ì¬ requirements.txtì™€ ì‹¤ì œ ì‚¬ìš© íŒ¨í‚¤ì§€ ë¹„êµ"""
    
    print("ğŸ” ë°±ì—”ë“œ ì½”ë“œì—ì„œ import ë¬¸ ë¶„ì„ ì¤‘...")
    imports = find_imports('backend')
    
    # ë‚´ì¥ ëª¨ë“ˆ í•„í„°ë§
    builtin_modules = get_builtin_modules()
    external_imports = [imp for imp in imports if imp not in builtin_modules]
    
    print(f"\nğŸ“¦ ì™¸ë¶€ íŒ¨í‚¤ì§€ importë“¤ ({len(external_imports)}ê°œ):")
    for imp in external_imports:
        print(f"  - {imp}")
    
    if len(imports) > len(external_imports):
        filtered_out = len(imports) - len(external_imports)
        print(f"\nğŸš« ë‚´ì¥ ëª¨ë“ˆ {filtered_out}ê°œ í•„í„°ë§ë¨")
    
    print("\nğŸ”„ pip íŒ¨í‚¤ì§€ëª…ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
    package_mapping = get_package_mapping()
    required_packages = set()
    
    for imp in external_imports:
        if imp in package_mapping:
            required_packages.add(package_mapping[imp])
            print(f"  {imp} â†’ {package_mapping[imp]}")
        else:
            print(f"  â“ {imp} â†’ (ë§¤í•‘ ì •ë³´ ì—†ìŒ, í™•ì¸ í•„ìš”)")
            required_packages.add(imp)  # ì¼ë‹¨ ì¶”ê°€
    
    # í˜„ì¬ requirements.txt ì½ê¸°
    current_packages = set()
    if os.path.exists('requirements.txt'):
        with open('requirements.txt', 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    package = line.split('==')[0].split('>=')[0].split('<=')[0]
                    current_packages.add(package)
    
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"  í˜„ì¬ requirements.txt: {len(current_packages)}ê°œ íŒ¨í‚¤ì§€")
    print(f"  ì‹¤ì œ í•„ìš”í•œ íŒ¨í‚¤ì§€: {len(required_packages)}ê°œ íŒ¨í‚¤ì§€")
    
    # ë¶ˆí•„ìš”í•œ íŒ¨í‚¤ì§€ ì°¾ê¸°
    unnecessary = current_packages - required_packages
    missing = required_packages - current_packages
    
    if unnecessary:
        print(f"\nâŒ ì œê±° ê°€ëŠ¥í•œ íŒ¨í‚¤ì§€ë“¤ ({len(unnecessary)}ê°œ):")
        for pkg in sorted(unnecessary):
            print(f"  - {pkg}")
    
    if missing:
        print(f"\nâ• ì¶”ê°€ í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ ({len(missing)}ê°œ):")
        for pkg in sorted(missing):
            print(f"  - {pkg}")
    
    # ìµœì í™”ëœ requirements.txt ìƒì„±
    print(f"\nğŸ’¾ requirements_minimal.txt ìƒì„± ì¤‘...")
    with open('requirements_minimal.txt', 'w') as f:
        f.write("# ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” íŒ¨í‚¤ì§€ë§Œ í¬í•¨\n")
        f.write("# ìë™ ìƒì„±ë¨ - requirements_analyzer.py\n\n")
        
        for package in sorted(required_packages):
            f.write(f"{package}\n")
    
    print("âœ… ì™„ë£Œ! requirements_minimal.txt íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. requirements_minimal.txt ë‚´ìš© ê²€í† ")
    print("2. ë²„ì „ ì •ë³´ ì¶”ê°€ (í•„ìš”ì‹œ)")
    print("3. requirements.txt êµì²´")
    print("4. í…ŒìŠ¤íŠ¸ í›„ ë°°í¬")

if __name__ == "__main__":
    analyze_requirements()
