{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Supabase and Vercel Infrastructure",
        "description": "Initialize the foundational infrastructure by setting up Supabase database with pgvector extension and Vercel deployment environment for the admin dashboard and serverless functions.",
        "details": "1. Create Supabase project and configure the following:\n   - Set up PostgreSQL database with pgvector extension enabled\n   - Create database schema for Character Profile, Worldview, Animation Set, Interaction, and Streaming Session models\n   - Configure authentication with role-based access control\n   - Set up storage buckets for character assets\n   - Enable Row Level Security policies\n\n2. Initialize Vercel project:\n   - Set up React-based SPA project structure\n   - Configure serverless functions for API endpoints\n   - Set up environment variables for service connections\n   - Create deployment pipelines with staging and production environments\n\n3. Connect Supabase to Vercel:\n   - Configure environment variables for Supabase connection\n   - Set up authentication hooks in the frontend\n   - Test database connection from serverless functions",
        "testStrategy": "1. Verify database schema creation with test queries\n2. Confirm pgvector extension is properly installed and functioning\n3. Test authentication flow with admin role permissions\n4. Validate storage bucket access and permissions\n5. Verify Vercel deployment pipeline with a simple test component\n6. Ensure serverless functions can connect to Supabase\n7. Run end-to-end test of basic data operations",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Admin Dashboard Core",
        "description": "Develop the basic admin dashboard with authentication, character profile management, and configuration interfaces.",
        "details": "1. Create authentication screens:\n   - Login page with email/password authentication\n   - Registration page with admin approval flow\n   - Password reset functionality\n   - MFA implementation\n\n2. Develop character management interface:\n   - Character listing page with filtering and sorting\n   - Character creation form with basic fields (name, description, status)\n   - Character editing capabilities\n   - Image upload for base character assets\n\n3. Implement basic configuration screens:\n   - Simple worldview definition interface\n   - Basic prompt management system\n   - Voice profile configuration\n\n4. Create navigation and layout:\n   - Responsive sidebar navigation\n   - Header with user profile and quick actions\n   - Dashboard overview with key metrics\n\nTechnology stack:\n- React for frontend\n- Supabase Auth for authentication\n- Redux or Context API for state management\n- React Router for navigation\n- Form libraries (Formik or React Hook Form)",
        "testStrategy": "1. Test authentication flows including login, logout, and password reset\n2. Verify role-based access control for admin features\n3. Test character CRUD operations with various input combinations\n4. Validate image upload functionality and storage\n5. Test responsive design across different device sizes\n6. Verify form validation and error handling\n7. Conduct usability testing with sample admin users",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Develop Character Response Engine with LangGraph",
        "description": "Implement the core AI response generation system using LangGraph for prompt management, response generation, and emotion classification.",
        "status": "in-progress",
        "dependencies": [
          1
        ],
        "priority": "high",
        "details": "1. Set up LangChain integration: âœ…\n   - Install and configure LangChain library\n   - Connect to appropriate LLM (OpenAI API)\n   - Implement prompt template system\n\n2. Transition to LangGraph architecture: ðŸ”„\n   - Remove FAISS/RAG implementation\n   - Implement LangGraph structure for character responses\n   - Create graph nodes for different processing steps\n   - Build state management within the graph\n\n3. Develop prompt management: âœ…\n   - Create prompt templates for different interaction types using Jinja2\n   - Implement prompt injection functionality\n   - Build system for storing and retrieving prompts from database\n\n4. Implement basic emotion classification: âœ… (Needs improvement)\n   - Create NLP-based classifier for tagging responses with emotional states\n   - Support 4-5 basic emotions (happy, sad, neutral, surprised)\n   - Connect emotion tags to response generation\n   - Future work: Refine emotion classification accuracy and expand emotion range\n\n5. Build memory system:\n   - Implement conversation history storage\n   - Create context window management\n   - Develop reference system for previous interactions\n\n6. Create admin CRUD interface for prompts and instructions:\n   - Develop UI for managing prompts in admin page\n   - Implement CRUD operations for instructions\n   - Build preview functionality for testing prompts\n   - Create version history for prompt changes\n\nCode example for LangGraph implementation:\n```javascript\nconst createCharacterGraph = (character) => {\n  const graph = new LangGraph();\n  \n  // Define nodes\n  const inputNode = graph.addNode('input', (state, input) => {\n    return { ...state, userMessage: input.message, userId: input.userId };\n  });\n  \n  const contextNode = graph.addNode('context', async (state) => {\n    // Get conversation history\n    const history = await getConversationHistory(state.userId, character.id);\n    return { ...state, conversationHistory: history };\n  });\n  \n  const promptNode = graph.addNode('prompt', async (state) => {\n    // Get prompt template from database\n    const promptTemplate = await getPromptTemplate(character.id, 'standard');\n    \n    // Format prompt with context\n    const formattedPrompt = formatPrompt(promptTemplate, {\n      character,\n      userMessage: state.userMessage,\n      conversationHistory: state.conversationHistory\n    });\n    \n    return { ...state, prompt: formattedPrompt };\n  });\n  \n  const llmNode = graph.addNode('llm', async (state) => {\n    // Generate response using LLM\n    const response = await generateLLMResponse(state.prompt);\n    return { ...state, response };\n  });\n  \n  const emotionNode = graph.addNode('emotion', (state) => {\n    // Extract emotion from response\n    const emotion = extractEmotion(state.response);\n    return { ...state, emotion };\n  });\n  \n  const outputNode = graph.addNode('output', (state) => {\n    return {\n      text: state.response,\n      emotion: state.emotion\n    };\n  });\n  \n  // Define edges\n  graph.addEdge(inputNode, contextNode);\n  graph.addEdge(contextNode, promptNode);\n  graph.addEdge(promptNode, llmNode);\n  graph.addEdge(llmNode, emotionNode);\n  graph.addEdge(emotionNode, outputNode);\n  \n  return graph;\n};\n```",
        "testStrategy": "1. Test LangGraph implementation with various character profiles and inputs\n2. Verify emotion classification accuracy across different response types\n3. Measure response generation time and optimize for performance\n4. Test prompt management CRUD operations in admin interface\n5. Validate context preservation across multiple interactions\n6. Verify memory system retains appropriate conversation history\n7. Test edge cases like very long inputs or unusual requests\n8. Conduct A/B testing of different prompt structures for quality",
        "subtasks": [
          {
            "id": "3.1",
            "title": "LangChain Integration",
            "description": "Set up LangChain with OpenAI API and implement prompt template system",
            "status": "completed"
          },
          {
            "id": "3.2",
            "title": "LangGraph Implementation",
            "description": "Implement LangGraph architecture to replace FAISS/RAG system",
            "status": "in-progress"
          },
          {
            "id": "3.3",
            "title": "Prompt Management with Jinja2",
            "description": "Finalize prompt templates and management system using Jinja2",
            "status": "completed"
          },
          {
            "id": "3.4",
            "title": "Emotion Classification Improvement",
            "description": "Enhance the basic emotion classification system for better accuracy and expanded emotion range",
            "status": "pending"
          },
          {
            "id": "3.5",
            "title": "Memory System Implementation",
            "description": "Build the conversation history storage and context management system",
            "status": "pending"
          },
          {
            "id": "3.6",
            "title": "Admin CRUD Interface for Prompts",
            "description": "Develop admin page interface for managing prompts and instructions",
            "status": "pending"
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Broadcast Tab and Motion Tag Video System",
        "description": "Develop the broadcast tab for local video playback with motion tags and real-time state transitions driven by TikTokLive chat and LLM responses.",
        "status": "pending",
        "dependencies": [
          1,
          2
        ],
        "priority": "medium",
        "details": "1. Implement the broadcast tab to play local video files from localhost/motion/filename.\n2. Store video metadata in a JSON file, with each video assigned a 'motion' tag: neutral (default), talking, or reaction. Each tag can map to multiple videos, but each video has only one tag.\n3. Integrate TikTokLive chat input: forward each chat to the character's LangGraph LLM and receive a response text and emotion tag.\n4. Play TTS audio for the response, and while audio is playing, display a video with the 'talking' tag.\n5. When TTS/audio streaming ends, automatically switch back to a 'neutral' video.\n6. If a reaction event is triggered (e.g., by a gift/chat), play a 'reaction' tagged video.\n7. Implement state management for video transitions and error handling for video/audio playback.\n8. Store AI-generated response text with session timestamp, character name, content, and output tag for each interaction.",
        "testStrategy": "Test video playback for each motion tag. Verify correct transitions between neutral, talking, and reaction videos based on chat and LLM response. Ensure TTS audio and talking video are synchronized. Test error handling for missing or failed video/audio files. Simulate TikTokLive chat and verify end-to-end flow.\n1. Test animation asset upload and storage\n2. Verify correct rendering of animations in different browsers\n3. Test state transitions between all emotion combinations\n4. Measure performance metrics for animation rendering\n5. Validate animation sequencing with timing tests\n6. Test fallback mechanisms for missing animations\n7. Verify canvas rendering quality at different resolutions\n8. Test animation system with various character asset styles\n9. Verify response data storage with correct timestamp, character name, content, and output tag",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Integrate Text-to-Speech System",
        "description": "Implement voice synthesis integration that converts AI-generated text responses into natural-sounding audio customized for each character.",
        "status": "pending",
        "dependencies": [
          3
        ],
        "priority": "medium",
        "details": "1. Select and integrate TTS service:\n   - Research and select appropriate TTS API (e.g., ElevenLabs)\n   - Implement API connection and authentication\n   - Create error handling and fallback mechanisms\n\n2. Develop voice profile management:\n   - Create database structure for storing voice profiles\n   - Build interface for configuring voice parameters\n   - Implement profile assignment to characters\n\n3. Implement text processing for TTS:\n   - Create text normalization for better speech output\n   - Implement SSML markup for emphasis and pauses\n   - Build text chunking for longer responses\n\n4. Create audio output handling:\n   - Implement audio buffer management\n   - Build audio playback system\n   - Create audio format conversion if needed\n\n5. Develop emotion modulation:\n   - Map emotion tags to voice modulation parameters\n   - Implement basic emotion effects (pitch, rate, volume)\n   - Create natural transitions between emotional states\n\n6. Implement response logging system:\n   - Store AI-generated responses with session timestamps\n   - Include character name, response content, and output tag\n   - Create indexing for efficient retrieval\n\nExample TTS integration code:\n```javascript\nclass TTSService {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.baseUrl = 'https://api.tts-service.com/v1/';  // Replace with actual TTS API\n    this.voiceProfiles = {};\n  }\n  \n  async loadVoiceProfile(characterId) {\n    this.voiceProfiles[characterId] = await fetchVoiceProfile(characterId);\n    return this.voiceProfiles[characterId];\n  }\n  \n  async generateSpeech(text, characterId, emotion = 'neutral') {\n    const profile = this.voiceProfiles[characterId] || await this.loadVoiceProfile(characterId);\n    const normalizedText = this.normalizeText(text);\n    const ssmlText = this.addEmotionMarkup(normalizedText, emotion, profile);\n    \n    try {\n      const response = await fetch(`${this.baseUrl}synthesize`, {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${this.apiKey}`,\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          text: ssmlText,\n          voice_id: profile.voiceId,\n          settings: this.getSettingsForEmotion(emotion, profile)\n        })\n      });\n      \n      if (!response.ok) throw new Error('TTS API error');\n      \n      const audioBlob = await response.blob();\n      \n      // Log the response with timestamp and metadata\n      await this.logResponse({\n        characterId,\n        characterName: profile.name,\n        content: text,\n        emotion: emotion,\n        timestamp: new Date().toISOString(),\n        sessionId: this.getCurrentSessionId()\n      });\n      \n      return URL.createObjectURL(audioBlob);\n    } catch (error) {\n      console.error('TTS generation failed:', error);\n      return this.getFallbackAudio(emotion);\n    }\n  }\n  \n  normalizeText(text) {\n    // Implement text normalization\n    return text;\n  }\n  \n  addEmotionMarkup(text, emotion, profile) {\n    // Add SSML markup based on emotion\n    return text;\n  }\n  \n  getSettingsForEmotion(emotion, profile) {\n    // Map emotion to voice settings\n    const settings = { ...profile.baseSettings };\n    \n    switch(emotion) {\n      case 'happy':\n        settings.pitch = profile.baseSettings.pitch * 1.1;\n        settings.rate = profile.baseSettings.rate * 1.05;\n        break;\n      case 'sad':\n        settings.pitch = profile.baseSettings.pitch * 0.95;\n        settings.rate = profile.baseSettings.rate * 0.9;\n        break;\n      // Add other emotions\n    }\n    \n    return settings;\n  }\n  \n  getFallbackAudio(emotion) {\n    // Return pre-generated fallback audio\n    return `/fallback-audio/${emotion}.mp3`;\n  }\n  \n  async logResponse(responseData) {\n    try {\n      // Store response in database with timestamp and metadata\n      await db.collection('character_responses').add(responseData);\n    } catch (error) {\n      console.error('Failed to log response:', error);\n    }\n  }\n  \n  getCurrentSessionId() {\n    // Get current session ID from the application context\n    return window.currentSessionId || 'unknown-session';\n  }\n}\n```",
        "testStrategy": "1. Test TTS API integration with various text inputs\n2. Verify voice profile configuration and storage\n3. Measure speech generation time and optimize if needed\n4. Test audio quality across different character voices\n5. Validate emotion modulation effects\n6. Test fallback mechanisms when TTS service fails\n7. Verify audio format compatibility with streaming system\n8. Conduct listening tests for naturalness and character fit\n9. Verify response logging with correct timestamps and metadata\n10. Test retrieval of stored responses by session, character, and timestamp",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement OBS Integration for Streaming",
        "description": "Develop the integration with OBS Studio to combine character animations and audio into a continuous live stream for TikTok Live.",
        "status": "pending",
        "dependencies": [
          4,
          5
        ],
        "priority": "medium",
        "details": "1. Set up OBS configuration:\n   - Create standard scene templates for character streams\n   - Configure browser sources for animation display\n   - Set up audio sources for TTS output\n   - Configure output settings for TikTok Live\n\n2. Implement OBS WebSocket API integration:\n   - Connect to OBS via obs-websocket protocol\n   - Create scene switching functionality\n   - Implement source visibility control\n   - Build audio level management\n\n3. Develop browser source content:\n   - Create HTML/CSS/JS package for animation display\n   - Implement WebSocket client for receiving animation commands\n   - Build animation rendering in browser context\n\n4. Create stream management system:\n   - Implement stream start/stop controls\n   - Build stream health monitoring\n   - Create automatic recovery procedures\n   - Develop stream metadata management\n\n5. Implement buffer animation system:\n   - Create transition animations for processing delays\n   - Implement thinking poses and idle animations\n   - Build queuing system for smooth content flow\n\n6. Implement session-based response logging:\n   - Create session initialization with unique ID and timestamp\n   - Log all AI responses with character name, content, and output tag\n   - Implement session summary generation\n   - Log viewer actions (likes, follows, gifts) in chat logs table with [action+details] format\n\nExample OBS WebSocket integration:\n```javascript\nclass OBSController {\n  constructor(config) {\n    this.config = config;\n    this.obs = null;\n    this.connected = false;\n    this.currentScene = null;\n    this.sessionId = null;\n    this.sessionStartTime = null;\n    this.chatLogs = []; // Store chat logs during session\n  }\n  \n  async connect() {\n    try {\n      this.obs = new OBSWebSocket();\n      await this.obs.connect({\n        address: this.config.address,\n        password: this.config.password\n      });\n      \n      this.connected = true;\n      this.currentScene = await this.obs.call('GetCurrentProgramScene');\n      \n      this.obs.on('ConnectionClosed', this.handleDisconnect.bind(this));\n      this.obs.on('StreamStateChanged', this.handleStreamState.bind(this));\n      \n      return true;\n    } catch (error) {\n      console.error('OBS connection failed:', error);\n      this.connected = false;\n      return false;\n    }\n  }\n  \n  async startSession(characterId, characterName) {\n    this.sessionId = generateUniqueId();\n    this.sessionStartTime = new Date().toISOString();\n    this.chatLogs = []; // Reset chat logs for new session\n    \n    // Log session start\n    await this.logSessionEvent({\n      type: 'session_start',\n      characterId,\n      characterName,\n      timestamp: this.sessionStartTime,\n      sessionId: this.sessionId\n    });\n    \n    return this.sessionId;\n  }\n  \n  async endSession() {\n    if (!this.sessionId) return;\n    \n    const sessionEndTime = new Date().toISOString();\n    \n    // Log session end\n    await this.logSessionEvent({\n      type: 'session_end',\n      timestamp: sessionEndTime,\n      sessionId: this.sessionId,\n      duration: calculateDuration(this.sessionStartTime, sessionEndTime)\n    });\n    \n    // Store all chat logs to database at session end\n    if (this.chatLogs.length > 0) {\n      await this.storeChatLogs(this.chatLogs, this.sessionId);\n    }\n    \n    this.sessionId = null;\n    this.sessionStartTime = null;\n    this.chatLogs = [];\n  }\n  \n  async logChatMessage(viewerId, content) {\n    // Add chat message to in-memory array during session\n    this.chatLogs.push({\n      viewerId: viewerId,\n      content: content,\n      timestamp: new Date().toISOString(),\n      sessionId: this.sessionId\n    });\n  }\n  \n  async logViewerAction(viewerId, actionType, details) {\n    // Add viewer action to in-memory array during session\n    this.chatLogs.push({\n      viewerId: viewerId,\n      content: `[${actionType}+${details}]`,\n      timestamp: new Date().toISOString(),\n      sessionId: this.sessionId,\n      isAction: true\n    });\n  }\n  \n  async storeChatLogs(chatLogs, sessionId) {\n    try {\n      // Store all chat logs in database at session end\n      const batch = db.batch();\n      \n      chatLogs.forEach(log => {\n        const docRef = db.collection('chat_logs').doc();\n        batch.set(docRef, {\n          viewerId: log.viewerId,\n          content: log.content,\n          timestamp: log.timestamp,\n          sessionId: sessionId,\n          isAction: log.isAction || false\n        });\n      });\n      \n      await batch.commit();\n      console.log(`Stored ${chatLogs.length} chat logs for session ${sessionId}`);\n    } catch (error) {\n      console.error('Failed to store chat logs:', error);\n    }\n  }\n  \n  async logResponse(responseData) {\n    if (!this.sessionId) return;\n    \n    // Add session metadata\n    const enrichedData = {\n      ...responseData,\n      sessionId: this.sessionId,\n      timestamp: new Date().toISOString()\n    };\n    \n    // Store in database\n    await db.collection('character_responses').add(enrichedData);\n  }\n  \n  async logSessionEvent(eventData) {\n    try {\n      await db.collection('session_events').add(eventData);\n    } catch (error) {\n      console.error('Failed to log session event:', error);\n    }\n  }\n  \n  async switchToScene(sceneName) {\n    if (!this.connected) await this.connect();\n    \n    try {\n      await this.obs.call('SetCurrentProgramScene', { sceneName });\n      this.currentScene = sceneName;\n      return true;\n    } catch (error) {\n      console.error('Scene switch failed:', error);\n      return false;\n    }\n  }\n  \n  async startStream() {\n    if (!this.connected) await this.connect();\n    \n    try {\n      await this.obs.call('StartStream');\n      return true;\n    } catch (error) {\n      console.error('Stream start failed:', error);\n      return false;\n    }\n  }\n  \n  async stopStream() {\n    if (!this.connected) return false;\n    \n    try {\n      await this.obs.call('StopStream');\n      return true;\n    } catch (error) {\n      console.error('Stream stop failed:', error);\n      return false;\n    }\n  }\n  \n  async updateBrowserSource(sourceName, url) {\n    if (!this.connected) await this.connect();\n    \n    try {\n      await this.obs.call('SetInputSettings', {\n        inputName: sourceName,\n        inputSettings: {\n          url: url\n        }\n      });\n      return true;\n    } catch (error) {\n      console.error('Browser source update failed:', error);\n      return false;\n    }\n  }\n  \n  handleDisconnect() {\n    this.connected = false;\n    // Attempt to reconnect\n    setTimeout(() => this.connect(), 5000);\n  }\n  \n  handleStreamState(event) {\n    // Handle stream state changes\n    console.log('Stream state changed:', event);\n  }\n}\n\nfunction generateUniqueId() {\n  return Date.now().toString(36) + Math.random().toString(36).substr(2);\n}\n\nfunction calculateDuration(startTime, endTime) {\n  return (new Date(endTime) - new Date(startTime)) / 1000; // in seconds\n}\n```",
        "testStrategy": "1. Test OBS WebSocket connection and authentication\n2. Verify scene switching functionality\n3. Test browser source updates with animation content\n4. Validate audio routing from TTS to OBS\n5. Measure stream start/stop reliability\n6. Test automatic recovery from connection failures\n7. Verify buffer animation system during processing delays\n8. Conduct end-to-end streaming test to TikTok test account\n9. Verify session-based response logging with correct timestamps\n10. Test retrieval of responses by session ID and timestamp\n11. Validate character name and output tag storage in response logs\n12. Verify chat logs are properly stored in the database at session end with timestamp, viewer ID, and content\n13. Test logging of viewer actions (likes, follows, gifts) in chat logs with [action+details] format\n14. Verify retrieval and filtering of chat logs by action type",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Develop TikTok Live Integration for Gifts",
        "description": "Implement integration with TikTok Live API to capture, process, and respond to audience Gifts in real-time, including forwarding chat to the character LLM and triggering reaction videos.",
        "status": "pending",
        "dependencies": [
          3,
          6
        ],
        "priority": "high",
        "details": "1. Integrate with the TikTok Live API to receive audience chat and gift events.\n2. Forward all chat messages to the character's LangGraph LLM and process the response.\n3. When a gift event is detected, play the mapped reaction video according to the gift type.\n4. Ensure that chat inputs are processed sequentially, with each response and reaction video played in order.\n5. Plan for future enhancements to allow the LLM to select which chats to respond to when chat volume is high (for now, all chats are sent to the LLM).\n6. Implement logging for chat and gift events, and optimize for low latency and real-time interaction.\n7. Store all AI-generated responses with session timestamp, character name, content, and output tag for each interaction.\n8. Implement a system to track which responses were triggered by gifts versus regular chat messages.\n9. Collect viewer chat messages during the session and store them in the database chat logs table at session end with timestamp, viewer ID, and content.\n10. Log viewer actions (likes, follows, gifts) in chat logs table with [action+details] format.\n11. Implement handlers for non-chat viewer actions (likes, follows) and log them in the same format.\n12. Integrate with ElevenLabs API's live streaming feature to enable real-time TTS playback of responses in the broadcast tab.",
        "testStrategy": "Test with simulated chat and gift events to verify correct LLM responses, reaction video playback, and sequential processing under various chat volumes. Verify system stability during extended sessions with mixed chat and gift events.\n1. Test TikTok Live API connection with test account\n2. Verify Super Chat message capture and processing\n3. Test chat history storage and retrieval\n4. Validate user identification across sessions\n5. Test reconnection logic with simulated disconnects\n6. Measure message processing performance under load\n7. Verify priority queue handling with multiple Super Chats\n8. Test admin monitoring interface functionality\n9. Verify response logging with correct timestamps and metadata\n10. Test retrieval of responses filtered by session, character, and event type\n11. Verify chat logs are properly stored in the database at session end with timestamp, viewer ID, and content\n12. Test logging of viewer actions (likes, follows, gifts) in chat logs with [action+details] format\n13. Verify retrieval and filtering of chat logs by action type\n14. Test handling of high-volume viewer actions during peak streaming periods\n15. Test ElevenLabs API live streaming integration for real-time TTS playback\n16. Verify audio streaming latency and performance under various network conditions",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Create End-to-End Integration System",
        "description": "Develop the system that connects all components (Character Engine, Animation System, TTS, OBS, and TikTok Live) into a cohesive workflow.",
        "status": "pending",
        "dependencies": [
          3,
          4,
          5,
          6,
          7
        ],
        "priority": "high",
        "details": "1. Design integration architecture:\n   - Create service communication patterns\n   - Define data flow between components\n   - Implement event-driven architecture\n\n2. Develop main orchestration service:\n   - Create central controller for managing component interactions\n   - Implement state management for system status\n   - Build error handling and recovery mechanisms\n\n3. Implement message processing pipeline:\n   - Create workflow from message receipt to response delivery\n   - Build parallel processing where appropriate\n   - Implement timeout and fallback mechanisms\n\n4. Create monitoring and logging system:\n   - Implement comprehensive logging across all components\n   - Build health check system for component status\n   - Create alerting for critical failures\n   - Store all AI-generated responses with session timestamp, character name, content, and output tag\n   - Collect viewer chat messages during session for storage in database at session end\n   - Log viewer actions (likes, follows, gifts) in chat logs table with [action+details] format\n\n5. Develop configuration management:\n   - Create centralized configuration system\n   - Implement environment-specific settings\n   - Build dynamic configuration updates\n\n6. Integrate ElevenLabs TTS live streaming:\n   - Implement ElevenLabs API client for live streaming TTS\n   - Create audio stream handling in broadcast tab\n   - Develop real-time audio playback system\n   - Implement error handling and fallback mechanisms for TTS streaming\n   - Optimize for low latency audio delivery\n\nExample orchestration service:\n```javascript\nclass VirtualCharacterOrchestrator {\n  constructor(config) {\n    this.config = config;\n    this.components = {};\n    this.status = 'initializing';\n    this.activeCharacter = null;\n    this.processingQueue = [];\n    this.currentSessionId = null;\n    this.chatLogs = []; // Store chat logs during session\n  }\n  \n  async initialize() {\n    try {\n      // Initialize all components\n      this.components.langGraph = new CharacterEngine(this.config.langGraph);\n      this.components.animationSystem = new AnimationSystem(this.config.animation);\n      this.components.ttsService = new TTSService(this.config.tts);\n      this.components.obsController = new OBSController(this.config.obs);\n      this.components.tikTokClient = new TikTokLiveClient(this.config.tikTok);\n      \n      // Connect components\n      await this.components.obsController.connect();\n      await this.components.tikTokClient.connect();\n      \n      // Set up event handlers\n      this.components.tikTokClient.onChat(this.handleChat.bind(this));\n      this.components.tikTokClient.onSuperChat(this.handleSuperChat.bind(this));\n      this.components.tikTokClient.onLike(this.handleLike.bind(this));\n      this.components.tikTokClient.onFollow(this.handleFollow.bind(this));\n      this.components.tikTokClient.onGift(this.handleGift.bind(this));\n      \n      this.status = 'ready';\n      return true;\n    } catch (error) {\n      console.error('Orchestrator initialization failed:', error);\n      this.status = 'error';\n      return false;\n    }\n  }\n  \n  async loadCharacter(characterId) {\n    try {\n      // Load character data\n      const characterData = await fetchCharacterData(characterId);\n      \n      // Initialize components with character data\n      await this.components.langGraph.loadCharacter(characterData);\n      await this.components.animationSystem.loadCharacter(characterData);\n      await this.components.ttsService.loadVoiceProfile(characterId);\n      \n      // Set up OBS scene\n      await this.components.obsController.switchToScene(characterData.defaultScene || 'DefaultCharacterScene');\n      await this.components.obsController.updateBrowserSource('CharacterAnimation', \n        `${this.config.baseUrl}/animation?characterId=${characterId}`);\n      \n      this.activeCharacter = characterData;\n      return true;\n    } catch (error) {\n      console.error('Character loading failed:', error);\n      return false;\n    }\n  }\n  \n  async startStream() {\n    if (!this.activeCharacter) {\n      console.error('No character loaded');\n      return false;\n    }\n    \n    try {\n      // Start session and get session ID\n      this.currentSessionId = await this.components.obsController.startSession(\n        this.activeCharacter.id,\n        this.activeCharacter.name\n      );\n      \n      // Reset chat logs for new session\n      this.chatLogs = [];\n      \n      // Start OBS streaming\n      await this.components.obsController.startStream();\n      \n      // Play intro animation\n      await this.playSequence('intro');\n      \n      this.status = 'streaming';\n      return true;\n    } catch (error) {\n      console.error('Stream start failed:', error);\n      return false;\n    }\n  }\n  \n  async stopStream() {\n    try {\n      // Play outro animation\n      await this.playSequence('outro');\n      \n      // Stop OBS streaming\n      await this.components.obsController.stopStream();\n      \n      // Store chat logs to database at session end\n      if (this.chatLogs.length > 0) {\n        await this.storeChatLogs();\n      }\n      \n      // End session\n      if (this.currentSessionId) {\n        await this.components.obsController.endSession();\n        this.currentSessionId = null;\n      }\n      \n      this.status = 'ready';\n      return true;\n    } catch (error) {\n      console.error('Stream stop failed:', error);\n      return false;\n    }\n  }\n  \n  async handleChat(chatMessage) {\n    // Log chat message for storage at session end\n    this.chatLogs.push({\n      viewerId: chatMessage.userId,\n      content: chatMessage.content,\n      timestamp: new Date().toISOString()\n    });\n    \n    // Add to processing queue\n    this.processingQueue.push({\n      type: 'chat',\n      data: chatMessage,\n      timestamp: Date.now()\n    });\n    \n    // Process if not already processing\n    if (this.processingQueue.length === 1) {\n      this.processNextInQueue();\n    }\n  }\n  \n  async handleLike(likeEvent) {\n    // Log like action for storage at session end\n    this.chatLogs.push({\n      viewerId: likeEvent.userId,\n      content: `[like+${likeEvent.likeCount}]`,\n      timestamp: new Date().toISOString(),\n      isAction: true\n    });\n  }\n  \n  async handleFollow(followEvent) {\n    // Log follow action for storage at session end\n    this.chatLogs.push({\n      viewerId: followEvent.userId,\n      content: `[follow+${followEvent.displayName}]`,\n      timestamp: new Date().toISOString(),\n      isAction: true\n    });\n  }\n  \n  async handleGift(giftEvent) {\n    // Log gift action for storage at session end\n    this.chatLogs.push({\n      viewerId: giftEvent.userId,\n      content: `[gift+${giftEvent.giftName}+${giftEvent.diamondCount}]`,\n      timestamp: new Date().toISOString(),\n      isAction: true\n    });\n    \n    // Add to processing queue\n    this.processingQueue.push({\n      type: 'gift',\n      data: giftEvent,\n      timestamp: Date.now()\n    });\n    \n    // Process if not already processing\n    if (this.processingQueue.length === 1) {\n      this.processNextInQueue();\n    }\n  }\n  \n  async handleSuperChat(superChat) {\n    // Log super chat message for storage at session end\n    this.chatLogs.push({\n      viewerId: superChat.userId,\n      content: superChat.content,\n      timestamp: new Date().toISOString(),\n      isSuperChat: true,\n      amount: superChat.amount\n    });\n    \n    // Add to processing queue\n    this.processingQueue.push({\n      type: 'superChat',\n      data: superChat,\n      timestamp: Date.now()\n    });\n    \n    // Process if not already processing\n    if (this.processingQueue.length === 1) {\n      this.processNextInQueue();\n    }\n  }\n  \n  async processNextInQueue() {\n    if (this.processingQueue.length === 0) return;\n    \n    const item = this.processingQueue[0];\n    \n    try {\n      if (item.type === 'chat') {\n        await this.processChat(item.data);\n      } else if (item.type === 'superChat') {\n        await this.processSuperChat(item.data);\n      } else if (item.type === 'gift') {\n        await this.processGift(item.data);\n      }\n      \n      // Remove processed item\n      this.processingQueue.shift();\n      \n      // Process next item if available\n      if (this.processingQueue.length > 0) {\n        this.processNextInQueue();\n      }\n    } catch (error) {\n      console.error('Processing failed:', error);\n      \n      // Remove failed item after certain retries\n      // For simplicity, we're removing immediately here\n      this.processingQueue.shift();\n      \n      if (this.processingQueue.length > 0) {\n        this.processNextInQueue();\n      }\n    }\n  }\n  \n  async processChat(chatMessage) {\n    try {\n      // Show thinking animation\n      await this.components.animationSystem.playAnimation('thinking');\n      \n      // Generate response\n      const response = await this.components.langGraph.generateResponse(\n        this.activeCharacter.id,\n        chatMessage.content,\n        chatMessage.userId\n      );\n      \n      // Extract emotion from response\n      const emotion = this.extractEmotion(response) || 'neutral';\n      \n      // Generate speech using ElevenLabs live streaming\n      const audioStream = await this.components.ttsService.generateLiveStreamSpeech(\n        response.text,\n        this.activeCharacter.id,\n        emotion\n      );\n      \n      // Play animation with streaming audio\n      await this.components.animationSystem.playAnimationWithStreamingAudio(\n        emotion,\n        audioStream\n      );\n      \n      // Log interaction with response data\n      await this.logInteraction({\n        characterId: this.activeCharacter.id,\n        characterName: this.activeCharacter.name,\n        userId: chatMessage.userId,\n        userMessage: chatMessage.content,\n        response: response.text,\n        emotion: emotion,\n        timestamp: new Date().toISOString(),\n        sessionId: this.currentSessionId,\n        outputTag: response.outputTag || emotion\n      });\n      \n      return true;\n    } catch (error) {\n      console.error('Chat processing failed:', error);\n      \n      // Play error animation\n      await this.components.animationSystem.playAnimation('confused');\n      \n      return false;\n    }\n  }\n  \n  async processGift(giftEvent) {\n    try {\n      // Show thinking animation\n      await this.components.animationSystem.playAnimation('thinking');\n      \n      // Generate response with gift context\n      const response = await this.components.langGraph.generateResponse(\n        this.activeCharacter.id,\n        `[User sent a gift: ${giftEvent.giftName} worth ${giftEvent.diamondCount} diamonds]`,\n        giftEvent.userId\n      );\n      \n      // Extract emotion from response\n      const emotion = this.extractEmotion(response) || 'excited';\n      \n      // Generate speech using ElevenLabs live streaming\n      const audioStream = await this.components.ttsService.generateLiveStreamSpeech(\n        response.text,\n        this.activeCharacter.id,\n        emotion\n      );\n      \n      // Play animation with streaming audio\n      await this.components.animationSystem.playAnimationWithStreamingAudio(\n        emotion,\n        audioStream\n      );\n      \n      // Log interaction with response data\n      await this.logInteraction({\n        characterId: this.activeCharacter.id,\n        characterName: this.activeCharacter.name,\n        userId: giftEvent.userId,\n        userMessage: `[Gift: ${giftEvent.giftName}, ${giftEvent.diamondCount} diamonds]`,\n        response: response.text,\n        emotion: emotion,\n        giftName: giftEvent.giftName,\n        giftValue: giftEvent.diamondCount,\n        timestamp: new Date().toISOString(),\n        sessionId: this.currentSessionId,\n        outputTag: response.outputTag || emotion\n      });\n      \n      return true;\n    } catch (error) {\n      console.error('Gift processing failed:', error);\n      \n      // Play error animation\n      await this.components.animationSystem.playAnimation('confused');\n      \n      return false;\n    }\n  }\n  \n  async processSuperChat(superChat) {\n    try {\n      // Show thinking animation\n      await this.components.animationSystem.playAnimation('thinking');\n      \n      // Generate response\n      const response = await this.components.langGraph.generateResponse(\n        this.activeCharacter.id,\n        superChat.content,\n        superChat.userId\n      );\n      \n      // Extract emotion from response\n      const emotion = this.extractEmotion(response) || 'neutral';\n      \n      // Generate speech using ElevenLabs live streaming\n      const audioStream = await this.components.ttsService.generateLiveStreamSpeech(\n        response.text,\n        this.activeCharacter.id,\n        emotion\n      );\n      \n      // Play animation with streaming audio\n      await this.components.animationSystem.playAnimationWithStreamingAudio(\n        emotion,\n        audioStream\n      );\n      \n      // Log interaction with response data\n      await this.logInteraction({\n        characterId: this.activeCharacter.id,\n        characterName: this.activeCharacter.name,\n        userId: superChat.userId,\n        userMessage: superChat.content,\n        response: response.text,\n        emotion: emotion,\n        superChatAmount: superChat.amount,\n        timestamp: new Date().toISOString(),\n        sessionId: this.currentSessionId,\n        outputTag: response.outputTag || emotion\n      });\n      \n      return true;\n    } catch (error) {\n      console.error('Super Chat processing failed:', error);\n      \n      // Play error animation\n      await this.components.animationSystem.playAnimation('confused');\n      \n      return false;\n    }\n  }\n  \n  extractEmotion(response) {\n    // Extract emotion tag from response\n    const match = response.text.match(/\\[emotion:\\s*([a-z]+)\\]/i);\n    return match ? match[1].toLowerCase() : null;\n  }\n  \n  async storeChatLogs() {\n    try {\n      // Store all chat logs in database at session end\n      const batch = db.batch();\n      \n      this.chatLogs.forEach(log => {\n        const docRef = db.collection('chat_logs').doc();\n        batch.set(docRef, {\n          viewerId: log.viewerId,\n          content: log.content,\n          timestamp: log.timestamp,\n          sessionId: this.currentSessionId,\n          isSuperChat: log.isSuperChat || false,\n          amount: log.amount || 0,\n          isAction: log.isAction || false\n        });\n      });\n      \n      await batch.commit();\n      console.log(`Stored ${this.chatLogs.length} chat logs for session ${this.currentSessionId}`);\n      \n      // Clear chat logs after storing\n      this.chatLogs = [];\n    } catch (error) {\n      console.error('Failed to store chat logs:', error);\n    }\n  }\n  \n  async playSequence(sequenceName) {\n    // Play predefined animation sequence\n    const sequence = this.activeCharacter.sequences[sequenceName];\n    if (!sequence) return;\n    \n    for (const step of sequence) {\n      if (step.animation) {\n        await this.components.animationSystem.playAnimation(step.animation);\n      }\n      if (step.audio) {\n        await this.components.ttsService.playAudio(step.audio);\n      }\n      if (step.delay) {\n        await new Promise(resolve => setTimeout(resolve, step.delay));\n      }\n    }\n  }\n  \n  async logInteraction(interaction) {\n    try {\n      // Store interaction in database\n      await db.collection('interactions').add({\n        ...interaction,\n        timestamp: new Date(),\n        sessionId: this.currentSessionId || 'unknown-session'\n      });\n      \n      // Store response separately with required metadata\n      await db.collection('character_responses').add({\n        characterId: interaction.characterId,\n        characterName: interaction.characterName,\n        content: interaction.response,\n        outputTag: interaction.outputTag,\n        timestamp: interaction.timestamp,\n        sessionId: interaction.sessionId\n      });\n    } catch (error) {\n      console.error('Failed to log interaction:', error);\n    }\n  }\n}\n```",
        "testStrategy": "1. Test end-to-end workflow with simulated Super Chat messages\n2. Verify component integration with mock services\n3. Test error handling and recovery mechanisms\n4. Measure end-to-end latency from message receipt to response\n5. Validate state management across different scenarios\n6. Test parallel processing capabilities\n7. Verify logging and monitoring functionality\n8. Conduct load testing with multiple simultaneous interactions\n9. Verify response storage with correct session timestamp, character name, content, and output tag\n10. Test retrieval and filtering of stored responses by various criteria\n11. Verify chat logs are properly stored in the database at session end with timestamp, viewer ID, and content\n12. Test logging of viewer actions (likes, follows, gifts) in chat logs with [action+details] format\n13. Verify retrieval and filtering of chat logs by action type\n14. Test handling of high-volume viewer actions during peak streaming periods\n15. Test ElevenLabs API live streaming integration for TTS\n16. Verify real-time audio playback in broadcast tab\n17. Measure audio streaming latency and quality under various network conditions\n18. Test error handling during audio stream interruptions\n19. Verify synchronization between animation and streaming audio",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Basic Analytics System",
        "description": "Develop the foundation for tracking, analyzing, and visualizing audience interaction data and character performance metrics.",
        "status": "pending",
        "dependencies": [
          7,
          8
        ],
        "priority": "medium",
        "details": "1. Create data collection system:\n   - Implement event-based logging for all interactions\n   - Create storage schema for analytics data\n   - Build data aggregation pipelines\n   - Store AI-generated responses with session timestamp, character name, content, and output tag\n   - Analyze viewer chat logs stored in the database at session end\n   - Track viewer actions (likes, follows, gifts) logged in chat logs with [action+details] format\n   - Track TTS streaming performance metrics (latency, errors, completion time)\n\n2. Develop basic metrics dashboard:\n   - Create UI for viewing key performance indicators\n   - Implement filtering and date range selection\n   - Build basic visualization components\n   - Add response analysis section with filtering by output tag\n   - Add chat analysis section with viewer engagement metrics\n   - Add viewer action analysis section with metrics for likes, follows, and gifts\n   - Add TTS performance section with streaming metrics\n\n3. Implement session analytics:\n   - Create session-based metrics calculation\n   - Build viewer statistics tracking\n   - Implement revenue tracking for Super Chats\n   - Track response patterns by output tag and emotion\n   - Analyze chat volume and engagement patterns\n   - Track viewer action patterns and correlate with engagement metrics\n   - Monitor TTS streaming performance during sessions\n\n4. Develop character performance metrics:\n   - Create engagement rate calculations\n   - Implement response quality metrics\n   - Build comparison tools across characters\n   - Analyze response patterns by output tag\n   - Correlate viewer chat patterns with character responses\n   - Analyze viewer actions (likes, follows, gifts) in relation to character responses\n   - Track TTS voice performance metrics by character\n\n5. Create export functionality:\n   - Implement CSV export for raw data\n   - Build report generation system\n   - Create scheduled reporting functionality\n   - Include response text export with metadata\n   - Include chat log export with viewer IDs and timestamps\n   - Include viewer action export with action types and details\n   - Include TTS performance metrics in exports\n\nExample analytics data collection:\n```javascript\nclass AnalyticsCollector {\n  constructor(config) {\n    this.config = config;\n    this.sessionData = {};\n    this.currentSessionId = null;\n  }\n  \n  startSession(characterId, characterName) {\n    this.currentSessionId = uuidv4();\n    this.sessionData = {\n      id: this.currentSessionId,\n      characterId,\n      characterName,\n      startTime: new Date(),\n      endTime: null,\n      viewerStats: {\n        peak: 0,\n        average: 0,\n        samples: [],\n        uniqueViewers: new Set()\n      },\n      interactionStats: {\n        total: 0,\n        superChats: 0,\n        superChatRevenue: 0,\n        responseTimeAvg: 0,\n        responseTimes: []\n      },\n      responseStats: {\n        byOutputTag: {},\n        byEmotion: {}\n      },\n      chatStats: {\n        totalMessages: 0,\n        uniqueChatters: new Set(),\n        messagesByViewer: {}\n      },\n      actionStats: {\n        likes: 0,\n        follows: 0,\n        gifts: 0,\n        giftRevenue: 0,\n        actionsByType: {},\n        actionsByViewer: {}\n      },\n      ttsStats: {\n        totalStreams: 0,\n        streamLatencyAvg: 0,\n        streamLatencies: [],\n        streamErrors: 0,\n        streamCompletionTimeAvg: 0,\n        streamCompletionTimes: []\n      },\n      technicalStats: {\n        errors: 0,\n        reconnects: 0\n      }\n    };\n    \n    // Start viewer count sampling\n    this.viewerSampleInterval = setInterval(() => {\n      this.sampleViewerCount();\n    }, 60000); // Sample every minute\n    \n    // Log session start\n    this.logEvent('session_start', {\n      characterId,\n      characterName,\n      sessionId: this.currentSessionId\n    });\n    \n    return this.currentSessionId;\n  }\n  \n  endSession() {\n    if (!this.currentSessionId) return;\n    \n    // Clear sampling interval\n    clearInterval(this.viewerSampleInterval);\n    \n    // Calculate final stats\n    this.sessionData.endTime = new Date();\n    this.sessionData.duration = (this.sessionData.endTime - this.sessionData.startTime) / 1000; // in seconds\n    \n    // Calculate average viewers if samples exist\n    if (this.sessionData.viewerStats.samples.length > 0) {\n      this.sessionData.viewerStats.average = this.sessionData.viewerStats.samples.reduce((sum, count) => sum + count, 0) / \n        this.sessionData.viewerStats.samples.length;\n    }\n    \n    // Calculate average response time if responses exist\n    if (this.sessionData.interactionStats.responseTimes.length > 0) {\n      this.sessionData.interactionStats.responseTimeAvg = \n        this.sessionData.interactionStats.responseTimes.reduce((sum, time) => sum + time, 0) / \n        this.sessionData.interactionStats.responseTimes.length;\n    }\n    \n    // Calculate average TTS stream latency if streams exist\n    if (this.sessionData.ttsStats.streamLatencies.length > 0) {\n      this.sessionData.ttsStats.streamLatencyAvg = \n        this.sessionData.ttsStats.streamLatencies.reduce((sum, latency) => sum + latency, 0) / \n        this.sessionData.ttsStats.streamLatencies.length;\n    }\n    \n    // Calculate average TTS stream completion time if streams exist\n    if (this.sessionData.ttsStats.streamCompletionTimes.length > 0) {\n      this.sessionData.ttsStats.streamCompletionTimeAvg = \n        this.sessionData.ttsStats.streamCompletionTimes.reduce((sum, time) => sum + time, 0) / \n        this.sessionData.ttsStats.streamCompletionTimes.length;\n    }\n    \n    // Convert Sets to counts for storage\n    this.sessionData.viewerStats.uniqueViewerCount = this.sessionData.viewerStats.uniqueViewers.size;\n    this.sessionData.chatStats.uniqueChatterCount = this.sessionData.chatStats.uniqueChatters.size;\n    \n    // Remove Set objects before storage\n    delete this.sessionData.viewerStats.uniqueViewers;\n    delete this.sessionData.chatStats.uniqueChatters;\n    \n    // Log session end\n    this.logEvent('session_end', {\n      characterId: this.sessionData.characterId,\n      characterName: this.sessionData.characterName,\n      sessionId: this.currentSessionId,\n      duration: this.sessionData.duration,\n      viewerStats: this.sessionData.viewerStats,\n      interactionStats: this.sessionData.interactionStats,\n      responseStats: this.sessionData.responseStats,\n      chatStats: this.sessionData.chatStats,\n      actionStats: this.sessionData.actionStats,\n      ttsStats: this.sessionData.ttsStats,\n      technicalStats: this.sessionData.technicalStats\n    });\n    \n    // Store session data\n    this.storeSessionData();\n    \n    this.currentSessionId = null;\n    return this.sessionData;\n  }\n  \n  logTTSStreamMetrics(metrics) {\n    if (!this.currentSessionId) return;\n    \n    // Update TTS stats\n    this.sessionData.ttsStats.totalStreams++;\n    \n    if (metrics.latency) {\n      this.sessionData.ttsStats.streamLatencies.push(metrics.latency);\n    }\n    \n    if (metrics.error) {\n      this.sessionData.ttsStats.streamErrors++;\n    }\n    \n    if (metrics.completionTime) {\n      this.sessionData.ttsStats.streamCompletionTimes.push(metrics.completionTime);\n    }\n    \n    // Log TTS stream event\n    this.logEvent('tts_stream', {\n      characterId: this.sessionData.characterId,\n      characterName: this.sessionData.characterName,\n      sessionId: this.currentSessionId,\n      latency: metrics.latency,\n      completionTime: metrics.completionTime,\n      error: metrics.error,\n      timestamp: new Date().toISOString()\n    });\n  }\n  \n  logChatMessage(chatMessage) {\n    if (!this.currentSessionId) return;\n    \n    // Update chat stats\n    this.sessionData.chatStats.totalMessages++;\n    this.sessionData.chatStats.uniqueChatters.add(chatMessage.userId);\n    \n    // Track messages by viewer\n    if (!this.sessionData.chatStats.messagesByViewer[chatMessage.userId]) {\n      this.sessionData.chatStats.messagesByViewer[chatMessage.userId] = 0;\n    }\n    this.sessionData.chatStats.messagesByViewer[chatMessage.userId]++;\n  }\n  \n  logViewerAction(action) {\n    if (!this.currentSessionId) return;\n    \n    // Extract action type and details from content format [type+details]\n    const match = action.content.match(/\\[([^+]+)\\+(.+)\\]/);\n    if (!match) return;\n    \n    const actionType = match[1];\n    const actionDetails = match[2];\n    \n    // Update action stats\n    if (!this.sessionData.actionStats.actionsByType[actionType]) {\n      this.sessionData.actionStats.actionsByType[actionType] = 0;\n    }\n    this.sessionData.actionStats.actionsByType[actionType]++;\n    \n    // Track actions by viewer\n    if (!this.sessionData.actionStats.actionsByViewer[action.viewerId]) {\n      this.sessionData.actionStats.actionsByViewer[action.viewerId] = {};\n    }\n    if (!this.sessionData.actionStats.actionsByViewer[action.viewerId][actionType]) {\n      this.sessionData.actionStats.actionsByViewer[action.viewerId][actionType] = 0;\n    }\n    this.sessionData.actionStats.actionsByViewer[action.viewerId][actionType]++;\n    \n    // Update specific action counters\n    switch (actionType) {\n      case 'like':\n        this.sessionData.actionStats.likes++;\n        break;\n      case 'follow':\n        this.sessionData.actionStats.follows++;\n        break;\n      case 'gift':\n        this.sessionData.actionStats.gifts++;\n        // Extract gift value if available\n        const giftParts = actionDetails.split('+');\n        if (giftParts.length > 1) {\n          const giftValue = parseInt(giftParts[1], 10) || 0;\n          this.sessionData.actionStats.giftRevenue += giftValue;\n        }\n        break;\n    }\n    \n    // Log action event\n    this.logEvent('viewer_action', {\n      characterId: this.sessionData.characterId,\n      characterName: this.sessionData.characterName,\n      sessionId: this.currentSessionId,\n      userId: action.viewerId,\n      actionType: actionType,\n      actionDetails: actionDetails,\n      timestamp: new Date().toISOString()\n    });\n  }\n  \n  async analyzeChatLogs(sessionId) {\n    try {\n      // Retrieve chat logs for the session from database\n      const chatLogs = await db.collection('chat_logs')\n        .where('sessionId', '==', sessionId)\n        .orderBy('timestamp')\n        .get();\n      \n      const analysis = {\n        totalMessages: 0,\n        uniqueViewers: new Set(),\n        messagesByViewer: {},\n        messagesByHour: {},\n        superChatCount: 0,\n        superChatRevenue: 0,\n        actions: {\n          likes: 0,\n          follows: 0,\n          gifts: 0,\n          giftRevenue: 0,\n          byType: {},\n          byViewer: {}\n        }\n      };\n      \n      chatLogs.forEach(doc => {\n        const log = doc.data();\n        \n        // Count unique viewers\n        analysis.uniqueViewers.add(log.viewerId);\n        \n        if (log.isAction) {\n          // Process viewer action\n          const match = log.content.match(/\\[([^+]+)\\+(.+)\\]/);\n          if (match) {\n            const actionType = match[1];\n            const actionDetails = match[2];\n            \n            // Count by action type\n            if (!analysis.actions.byType[actionType]) {\n              analysis.actions.byType[actionType] = 0;\n            }\n            analysis.actions.byType[actionType]++;\n            \n            // Count by viewer\n            if (!analysis.actions.byViewer[log.viewerId]) {\n              analysis.actions.byViewer[log.viewerId] = {};\n            }\n            if (!analysis.actions.byViewer[log.viewerId][actionType]) {\n              analysis.actions.byViewer[log.viewerId][actionType] = 0;\n            }\n            analysis.actions.byViewer[log.viewerId][actionType]++;\n            \n            // Update specific action counters\n            switch (actionType) {\n              case 'like':\n                analysis.actions.likes++;\n                break;\n              case 'follow':\n                analysis.actions.follows++;\n                break;\n              case 'gift':\n                analysis.actions.gifts++;\n                // Extract gift value if available\n                const giftParts = actionDetails.split('+');\n                if (giftParts.length > 1) {\n                  const giftValue = parseInt(giftParts[1], 10) || 0;\n                  analysis.actions.giftRevenue += giftValue;\n                }\n                break;\n            }\n          }\n        } else {\n          // Process chat message\n          analysis.totalMessages++;\n          \n          // Count messages by viewer\n          if (!analysis.messagesByViewer[log.viewerId]) {\n            analysis.messagesByViewer[log.viewerId] = 0;\n          }\n          analysis.messagesByViewer[log.viewerId]++;\n          \n          // Count messages by hour\n          const hour = new Date(log.timestamp).getHours();\n          if (!analysis.messagesByHour[hour]) {\n            analysis.messagesByHour[hour] = 0;\n          }\n          analysis.messagesByHour[hour]++;\n          \n          // Count super chats\n          if (log.isSuperChat) {\n            analysis.superChatCount++;\n            analysis.superChatRevenue += log.amount || 0;\n          }\n        }\n      });\n      \n      // Convert Set to count\n      analysis.uniqueViewerCount = analysis.uniqueViewers.size;\n      delete analysis.uniqueViewers;\n      \n      return analysis;\n    } catch (error) {\n      console.error('Failed to analyze chat logs:', error);\n      return null;\n    }\n  }\n  \n  async logInteraction(interaction) {\n    if (!this.currentSessionId) return;\n    \n    // Update interaction stats\n    this.sessionData.interactionStats.total++;\n    \n    if (interaction.superChatAmount > 0) {\n      this.sessionData.interactionStats.superChats++;\n      this.sessionData.interactionStats.superChatRevenue += interaction.superChatAmount;\n    }\n    \n    // Calculate and store response time\n    const responseTime = interaction.responseTime || 0;\n    this.sessionData.interactionStats.responseTimes.push(responseTime);\n    \n    // Track response by output tag\n    const outputTag = interaction.outputTag || 'unknown';\n    if (!this.sessionData.responseStats.byOutputTag[outputTag]) {\n      this.sessionData.responseStats.byOutputTag[outputTag] = 0;\n    }\n    this.sessionData.responseStats.byOutputTag[outputTag]++;\n    \n    // Track response by emotion\n    const emotion = interaction.emotion || 'neutral';\n    if (!this.sessionData.responseStats.byEmotion[emotion]) {\n      this.sessionData.responseStats.byEmotion[emotion] = 0;\n    }\n    this.sessionData.responseStats.byEmotion[emotion]++;\n    \n    // Log interaction event\n    this.logEvent('interaction', {\n      characterId: this.sessionData.characterId,\n      characterName: this.sessionData.characterName,\n      sessionId: this.currentSessionId,\n      interactionId: interaction.id,\n      userId: interaction.userId,\n      superChatAmount: interaction.superChatAmount,\n      responseTime: responseTime,\n      outputTag: outputTag,\n      emotion: emotion,\n      timestamp: new Date().toISOString()\n    });\n    \n    // Store response with required metadata\n    this.storeResponse({\n      characterId: this.sessionData.characterId,\n      characterName: this.sessionData.characterName,\n      content: interaction.response,\n      outputTag: outputTag,\n      timestamp: new Date().toISOString(),\n      sessionId: this.currentSessionId\n    });\n  }\n  \n  async storeResponse(responseData) {\n    try {\n      // Store response in database\n      await db.collection('character_responses').add(responseData);\n    } catch (error) {\n      console.error('Failed to store response:', error);\n    }\n  }\n  \n  logError(error) {\n    if (!this.currentSessionId) return;\n    \n    // Update error count\n    this.sessionData.technicalStats.errors++;\n    \n    // Log error event\n    this.logEvent('error', {\n      characterId: this.sessionData.characterId,\n      characterName: this.sessionData.characterName,\n      sessionId: this.currentSessionId,\n      errorType: error.type,\n      errorMessage: error.message,\n      component: error.component\n    });\n  }\n  \n  async logEvent(eventType, eventData) {\n    try {\n      // Store event in database\n      await db.collection('analytics_events').add({\n        type: eventType,\n        data: eventData,\n        timestamp: new Date()\n      });\n    } catch (error) {\n      console.error('Failed to log analytics event:', error);\n    }\n  }\n  \n  async storeSessionData() {\n    try {\n      // Store complete session data\n      await db.collection('streaming_sessions').doc(this.currentSessionId).set(this.sessionData);\n    } catch (error) {\n      console.error('Failed to store session data:', error);\n    }\n  }\n}\n```",
        "testStrategy": "1. Test data collection with simulated events\n2. Verify metrics calculation accuracy\n3. Test dashboard rendering with various data sets\n4. Validate filtering and date range functionality\n5. Test export functionality for different formats\n6. Verify real-time updates during active sessions\n7. Test data aggregation for historical analysis\n8. Validate report generation functionality\n9. Test response storage with correct timestamps and metadata\n10. Verify filtering and retrieval of responses by output tag\n11. Test character response pattern analysis functionality\n12. Verify chat log analysis with timestamp, viewer ID, and content data\n13. Test correlation between chat patterns and character responses\n14. Test viewer action logging and analysis with [action+details] format\n15. Verify filtering and retrieval of chat logs by action type\n16. Test correlation between viewer actions and character responses\n17. Validate metrics for likes, follows, and gifts in analytics dashboard\n18. Test TTS streaming metrics collection and analysis\n19. Verify latency and completion time calculations for TTS streams\n20. Test TTS performance visualization in analytics dashboard\n21. Validate TTS metrics export functionality",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement 24/7 Operation Capabilities",
        "description": "Develop the monitoring, alerting, and automatic recovery systems needed for continuous 24/7 operation of virtual character streams.",
        "status": "pending",
        "dependencies": [
          6,
          8
        ],
        "priority": "medium",
        "details": "1. Create comprehensive monitoring system:\n   - Implement health checks for all components\n   - Create heartbeat mechanism for detecting failures\n   - Build logging system for operational events\n   - Monitor response storage and retrieval functionality\n   - Monitor chat log storage at session end\n   - Monitor viewer action logging functionality\n   - Monitor ElevenLabs TTS streaming performance and availability\n\n2. Develop alerting framework:\n   - Implement notification system for critical issues\n   - Create escalation paths for different severity levels\n   - Build alert suppression for known issues\n   - Add alerts for response storage failures\n   - Add alerts for chat log storage failures\n   - Add alerts for viewer action logging failures\n   - Add alerts for TTS streaming failures or degraded performance\n\n3. Implement automatic recovery procedures:\n   - Create service restart capabilities\n   - Implement fallback mechanisms for component failures\n   - Build self-healing processes for common issues\n   - Ensure response data integrity during recovery\n   - Implement chat log backup and recovery mechanisms\n   - Ensure viewer action logs are preserved during recovery\n   - Develop TTS streaming fallback options (cached audio, alternative TTS service)\n\n4. Develop scheduled maintenance system:\n   - Create maintenance window management\n   - Implement graceful shutdown and restart procedures\n   - Build placeholder content for maintenance periods\n   - Ensure proper session closure with response data preservation\n   - Ensure chat logs are properly stored before maintenance\n   - Ensure viewer action logs are properly stored before maintenance\n   - Coordinate maintenance with ElevenLabs API availability\n\n5. Create performance optimization:\n   - Implement resource usage monitoring\n   - Build automatic scaling for high-load periods\n   - Create caching strategies for common operations\n   - Optimize response storage and retrieval for high volume\n   - Optimize chat log batch storage for large sessions\n   - Optimize viewer action log processing for high-volume events\n   - Implement TTS streaming optimization for low-latency delivery\n\nExample monitoring and recovery system:\n```javascript\nclass SystemMonitor {\n  constructor(config) {\n    this.config = config;\n    this.components = {};\n    this.status = {};\n    this.alertHandlers = [];\n    this.recoveryHandlers = {};\n    this.dataIntegrityChecks = {};\n  }\n  \n  registerComponent(componentId, component, healthCheckFn, recoveryFn, dataIntegrityCheckFn) {\n    this.components[componentId] = component;\n    this.status[componentId] = {\n      healthy: true,\n      lastCheck: null,\n      lastError: null,\n      recoveryAttempts: 0\n    };\n    \n    // Store health check function\n    this.components[componentId].healthCheck = healthCheckFn;\n    \n    // Store recovery function if provided\n    if (recoveryFn) {\n      this.recoveryHandlers[componentId] = recoveryFn;\n    }\n    \n    // Store data integrity check function if provided\n    if (dataIntegrityCheckFn) {\n      this.dataIntegrityChecks[componentId] = dataIntegrityCheckFn;\n    }\n  }\n  \n  onAlert(handler) {\n    this.alertHandlers.push(handler);\n  }\n  \n  startMonitoring() {\n    // Start health check intervals for each component\n    Object.keys(this.components).forEach(componentId => {\n      const interval = this.config.checkIntervals[componentId] || this.config.defaultCheckInterval;\n      \n      setInterval(() => {\n        this.checkComponentHealth(componentId);\n      }, interval);\n      \n      // If component has data integrity check, schedule it\n      if (this.dataIntegrityChecks[componentId]) {\n        const integrityInterval = this.config.integrityCheckIntervals[componentId] || \n                                 this.config.defaultIntegrityCheckInterval;\n        \n        setInterval(() => {\n          this.checkDataIntegrity(componentId);\n        }, integrityInterval);\n      }\n    });\n    \n    console.log('System monitoring started');\n  }\n  \n  async checkComponentHealth(componentId) {\n    const component = this.components[componentId];\n    if (!component || !component.healthCheck) return;\n    \n    try {\n      const healthy = await component.healthCheck();\n      const previousStatus = this.status[componentId].healthy;\n      \n      this.status[componentId].healthy = healthy;\n      this.status[componentId].lastCheck = new Date();\n      \n      // If status changed from healthy to unhealthy\n      if (previousStatus && !healthy) {\n        this.handleComponentFailure(componentId);\n      }\n      \n      // If status changed from unhealthy to healthy\n      if (!previousStatus && healthy) {\n        this.handleComponentRecovery(componentId);\n      }\n    } catch (error) {\n      this.status[componentId].healthy = false;\n      this.status[componentId].lastCheck = new Date();\n      this.status[componentId].lastError = error.message;\n      \n      this.handleComponentFailure(componentId, error);\n    }\n  }\n  \n  async checkDataIntegrity(componentId) {\n    if (!this.dataIntegrityChecks[componentId]) return;\n    \n    try {\n      const result = await this.dataIntegrityChecks[componentId]();\n      \n      if (!result.valid) {\n        console.error(`Data integrity check failed for ${componentId}:`, result.issues);\n        \n        // Trigger data integrity alert\n        this.triggerAlert({\n          type: 'data_integrity_failure',\n          componentId: componentId,\n          issues: result.issues,\n          timestamp: new Date()\n        });\n        \n        // Attempt to fix if repair function provided\n        if (result.repair && typeof result.repair === 'function') {\n          try {\n            await result.repair();\n            console.log(`Data integrity repair attempted for ${componentId}`);\n          } catch (repairError) {\n            console.error(`Data integrity repair failed for ${componentId}:`, repairError);\n          }\n        }\n      }\n    } catch (error) {\n      console.error(`Data integrity check error for ${componentId}:`, error);\n    }\n  }\n  \n  async handleComponentFailure(componentId, error) {\n    console.error(`Component ${componentId} is unhealthy:`, error || 'health check failed');\n    \n    // Trigger alerts\n    this.triggerAlert({\n      type: 'component_failure',\n      componentId: componentId,\n      error: error ? error.message : 'health check failed',\n      timestamp: new Date()\n    });\n    \n    // Attempt recovery if handler exists\n    if (this.recoveryHandlers[componentId]) {\n      this.status[componentId].recoveryAttempts++;\n      \n      // Check if max recovery attempts exceeded\n      if (this.status[componentId].recoveryAttempts <= this.config.maxRecoveryAttempts) {\n        console.log(`Attempting recovery for ${componentId} (attempt ${this.status[componentId].recoveryAttempts})`);\n        \n        try {\n          await this.recoveryHandlers[componentId]();\n          console.log(`Recovery attempt for ${componentId} initiated`);\n        } catch (recoveryError) {\n          console.error(`Recovery attempt for ${componentId} failed:`, recoveryError);\n          \n          // Trigger recovery failure alert\n          this.triggerAlert({\n            type: 'recovery_failure',\n            componentId: componentId,\n            error: recoveryError.message,\n            attempts: this.status[componentId].recoveryAttempts,\n            timestamp: new Date()\n          });\n        }\n      } else {\n        console.error(`Max recovery attempts reached for ${componentId}`);\n        \n        // Trigger max attempts alert\n        this.triggerAlert({\n          type: 'max_recovery_attempts',\n          componentId: componentId,\n          attempts: this.status[componentId].recoveryAttempts,\n          timestamp: new Date()\n        });\n      }\n    }\n  }\n  \n  handleComponentRecovery(componentId) {\n    console.log(`Component ${componentId} recovered`);\n    \n    // Reset recovery attempts\n    this.status[componentId].recoveryAttempts = 0;\n    \n    // Trigger recovery alert\n    this.triggerAlert({\n      type: 'component_recovery',\n      componentId: componentId,\n      timestamp: new Date()\n    });\n  }\n  \n  triggerAlert(alert) {\n    // Notify all alert handlers\n    this.alertHandlers.forEach(handler => {\n      try {\n        handler(alert);\n      } catch (error) {\n        console.error('Alert handler error:', error);\n      }\n    });\n    \n    // Log alert\n    this.logAlert(alert);\n  }\n  \n  async logAlert(alert) {\n    try {\n      // Store alert in database\n      await db.collection('system_alerts').add(alert);\n    } catch (error) {\n      console.error('Failed to log alert:', error);\n    }\n  }\n  \n  getSystemStatus() {\n    const overallHealthy = Object.values(this.status).every(status => status.healthy);\n    \n    return {\n      healthy: overallHealthy,\n      components: this.status,\n      timestamp: new Date()\n    };\n  }\n  \n  // Example health check for TTS streaming service\n  static ttsStreamingHealthCheck(ttsService) {\n    return async () => {\n      try {\n        // Test ElevenLabs API connectivity with a simple request\n        const result = await ttsService.testConnection();\n        return result.status === 'ok';\n      } catch (error) {\n        console.error('TTS streaming health check failed:', error);\n        return false;\n      }\n    };\n  }\n  \n  // Example recovery function for TTS streaming service\n  static ttsStreamingRecovery(ttsService) {\n    return async () => {\n      try {\n        // Attempt to reinitialize the TTS service\n        await ttsService.reinitialize();\n        \n        // Test if recovery was successful\n        const testResult = await ttsService.testConnection();\n        return testResult.status === 'ok';\n      } catch (error) {\n        console.error('TTS streaming recovery failed:', error);\n        throw error;\n      }\n    };\n  }\n  \n  // Example data integrity check for response storage\n  static responseStorageIntegrityCheck() {\n    return async () => {\n      try {\n        // Check for incomplete response records\n        const incompleteResponses = await db.collection('character_responses')\n          .where('content', '==', null)\n          .limit(100)\n          .get();\n        \n        // Check for responses without required metadata\n        const missingMetadataResponses = await db.collection('character_responses')\n          .where('timestamp', '==', null)\n          .limit(100)\n          .get();\n        \n        const issues = [];\n        \n        if (!incompleteResponses.empty) {\n          issues.push({\n            type: 'incomplete_responses',\n            count: incompleteResponses.size\n          });\n        }\n        \n        if (!missingMetadataResponses.empty) {\n          issues.push({\n            type: 'missing_metadata',\n            count: missingMetadataResponses.size\n          });\n        }\n        \n        return {\n          valid: issues.length === 0,\n          issues: issues,\n          repair: issues.length > 0 ? async () => {\n            // Implement repair logic here\n            // For example, mark incomplete records for review\n            const batch = db.batch();\n            \n            incompleteResponses.forEach(doc => {\n              batch.update(doc.ref, { needsReview: true });\n            });\n            \n            missingMetadataResponses.forEach(doc => {\n              batch.update(doc.ref, { needsReview: true });\n            });\n            \n            await batch.commit();\n          } : null\n        };\n      } catch (error) {\n        console.error('Response storage integrity check failed:', error);\n        return {\n          valid: false,\n          issues: [{ type: 'check_failed', error: error.message }]\n        };\n      }\n    };\n  }\n  \n  // Example data integrity check for chat logs\n  static chatLogIntegrityCheck() {\n    return async () => {\n      try {\n        // Check for incomplete chat log records\n        const incompleteLogs = await db.collection('chat_logs')\n          .where('content', '==', null)\n          .limit(100)\n          .get();\n        \n        // Check for chat logs without required metadata\n        const missingMetadataLogs = await db.collection('chat_logs')\n          .where('timestamp', '==', null)\n          .limit(100)\n          .get();\n        \n        // Check for action logs with invalid format\n        const invalidActionLogs = await db.collection('chat_logs')\n          .where('isAction', '==', true)\n          .limit(200)\n          .get();\n        \n        const invalidActions = [];\n        invalidActionLogs.forEach(doc => {\n          const log = doc.data();\n          if (!log.content.match(/\\[([^+]+)\\+(.+)\\]/)) {\n            invalidActions.push(doc.id);\n          }\n        });\n        \n        const issues = [];\n        \n        if (!incompleteLogs.empty) {\n          issues.push({\n            type: 'incomplete_chat_logs',\n            count: incompleteLogs.size\n          });\n        }\n        \n        if (!missingMetadataLogs.empty) {\n          issues.push({\n            type: 'missing_metadata_chat_logs',\n            count: missingMetadataLogs.size\n          });\n        }\n        \n        if (invalidActions.length > 0) {\n          issues.push({\n            type: 'invalid_action_format',\n            count: invalidActions.length\n          });\n        }\n        \n        return {\n          valid: issues.length === 0,\n          issues: issues,\n          repair: issues.length > 0 ? async () => {\n            // Implement repair logic here\n            const batch = db.batch();\n            \n            incompleteLogs.forEach(doc => {\n              batch.update(doc.ref, { needsReview: true });\n            });\n            \n            missingMetadataLogs.forEach(doc => {\n              batch.update(doc.ref, { needsReview: true });\n            });\n            \n            // Mark invalid action logs for review\n            invalidActions.forEach(docId => {\n              const docRef = db.collection('chat_logs').doc(docId);\n              batch.update(docRef, { needsReview: true, invalidActionFormat: true });\n            });\n            \n            await batch.commit();\n          } : null\n        };\n      } catch (error) {\n        console.error('Chat log integrity check failed:', error);\n        return {\n          valid: false,\n          issues: [{ type: 'check_failed', error: error.message }]\n        };\n      }\n    };\n  }\n}\n```",
        "testStrategy": "1. Test health check functionality for each component\n2. Verify alerting system with simulated failures\n3. Test automatic recovery procedures\n4. Validate monitoring dashboard accuracy\n5. Test system under various failure scenarios\n6. Verify graceful shutdown and restart procedures\n7. Test resource usage monitoring and optimization\n8. Conduct long-running stability tests (24+ hours)\n9. Test response data integrity checks and repair mechanisms\n10. Verify session data preservation during system failures\n11. Test response storage and retrieval under high load conditions\n12. Test chat log storage at session end with various session durations\n13. Verify chat log integrity checks and repair mechanisms\n14. Test chat log backup and recovery procedures\n15. Test viewer action logging with [action+details] format\n16. Verify viewer action log integrity checks and repair mechanisms\n17. Test handling of high-volume viewer actions during peak streaming periods\n18. Verify proper storage of viewer action logs during system recovery\n19. Test ElevenLabs API live streaming health checks\n20. Verify TTS streaming recovery mechanisms\n21. Test TTS streaming fallback options\n22. Measure TTS streaming performance under various network conditions\n23. Test TTS streaming error handling and recovery\n24. Verify system stability during TTS streaming interruptions",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ê³ ë„í™”",
        "description": "Supabase ë°ì´í„°ë² ì´ìŠ¤ì˜ ìŠ¤í‚¤ë§ˆë¥¼ ê°œì„ í•˜ê³  RLS, ì œì•½ ì¡°ê±´, ì¸ë±ìŠ¤ ë“±ì„ ì¶”ê°€í•˜ì—¬ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "details": "### 1. RLS(Row Level Security) í™œì„±í™” (ê³ ë„í™”)\n- [ ] RLS í™œì„±í™” (í˜„ìž¬ëŠ” í”„ë¡ íŠ¸ì—”ë“œ ì¸ì¦ ì´ìŠˆë¡œ ìž„ì‹œ ë¹„í™œì„±í™” ì¤‘)\n- [ ] ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ ì •ì±… ì •ì˜\n  - ê´€ë¦¬ìž: ëª¨ë“  CRUD ê¶Œí•œ\n  - ì—ë””í„°: ìƒì„±, ì½ê¸°, ì—…ë°ì´íŠ¸ ê¶Œí•œ\n  - ë·°ì–´: ì½ê¸° ì „ìš© ê¶Œí•œ\n- [ ] ì¸ì¦/ì¸ê°€ ì •ì±… í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìž‘ì„±\n\n### 2. ë°ì´í„° ë¬´ê²°ì„± ê°•í™”\n- [ ] ì™¸ëž˜ í‚¤ ì œì•½ ì¡°ê±´ ì¶”ê°€\n  - chat_logs.character_id â†’ characters.id\n  - live_sessions.character_id â†’ characters.id\n  - chat_logs.session_id â†’ live_sessions.id\n- [ ] NOT NULL ì œì•½ ì¡°ê±´ ì¶”ê°€\n  - í•„ìˆ˜ í•„ë“œì— ëŒ€í•œ NOT NULL ì œì•½ ì¡°ê±´ ì¶”ê°€\n  - ê¸°ë³¸ê°’ ì„¤ì • ê²€í† \n- [ ] CHECK ì œì•½ ì¡°ê±´ ì¶”ê°€\n  - status, emotion í•„ë“œì— ëŒ€í•œ ìœ íš¨ì„± ê²€ì‚¬\n\n### 3. ì„±ëŠ¥ ìµœì í™”\n- [ ] ì¸ë±ìŠ¤ ì¶”ê°€\n  - ìžì£¼ ê²€ìƒ‰ë˜ëŠ” ì»¬ëŸ¼ì— ëŒ€í•œ ì¸ë±ìŠ¤ ì¶”ê°€\n  - ì™¸ëž˜ í‚¤ ì»¬ëŸ¼ì— ëŒ€í•œ ì¸ë±ìŠ¤ ì¶”ê°€\n  - chat_logs í…Œì´ë¸”ì˜ timestamp, viewer_id, session_idì— ì¸ë±ìŠ¤ ì¶”ê°€\n  - chat_logs í…Œì´ë¸”ì˜ isAction í•„ë“œì— ì¸ë±ìŠ¤ ì¶”ê°€\n- [ ] íŒŒí‹°ì…”ë‹ ì „ëžµ ìˆ˜ë¦½ (chat_logs í…Œì´ë¸” ëŒ€ìƒ)\n  - ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ ì ìš© ê²€í† \n\n### 4. í™•ìž¥ì„± ê³ ë ¤\n- [ ] Full-Text Search ì¸ë±ìŠ¤ ì¶”ê°€\n- [ ] JSONB í•„ë“œì— ëŒ€í•œ GIN ì¸ë±ìŠ¤ ì¶”ê°€\n\n### 5. í”„ë¡¬í”„íŠ¸ ë° ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ê´€ë¦¬ í…Œì´ë¸” ì¶”ê°€\n- [ ] prompts í…Œì´ë¸” ìƒì„±\n  - id, title, content, character_id, created_at, updated_at í•„ë“œ í¬í•¨\n  - ë²„ì „ ê´€ë¦¬ë¥¼ ìœ„í•œ version í•„ë“œ ì¶”ê°€\n- [ ] instructions í…Œì´ë¸” ìƒì„±\n  - id, title, content, character_id, created_at, updated_at í•„ë“œ í¬í•¨\n  - í™œì„±í™” ìƒíƒœë¥¼ ìœ„í•œ is_active í•„ë“œ ì¶”ê°€\n\n### 6. AI ì‘ë‹µ ì €ìž¥ì„ ìœ„í•œ í…Œì´ë¸” êµ¬ì¡° ê°œì„ \n- [ ] character_responses í…Œì´ë¸” ìƒì„±\n  - id, character_id, character_name, content, output_tag, timestamp, session_id í•„ë“œ í¬í•¨\n  - ì„¸ì…˜ë³„ íƒ€ìž„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ì¸ë±ìŠ¤ ì¶”ê°€\n  - ìºë¦­í„° ID ë° ì¶œë ¥ íƒœê·¸ ê¸°ë°˜ ì¸ë±ìŠ¤ ì¶”ê°€\n- [ ] ì‘ë‹µ ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ìµœì í™”\n  - ì„¸ì…˜ë³„, ìºë¦­í„°ë³„, íƒœê·¸ë³„ ê²€ìƒ‰ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n  - ì‹œê°„ ë²”ìœ„ ê¸°ë°˜ ê²€ìƒ‰ ìµœì í™”\n\n### 7. ì±„íŒ… ë¡œê·¸ í…Œì´ë¸” êµ¬ì¡° ìµœì í™”\n- [ ] chat_logs í…Œì´ë¸” êµ¬ì¡° ê°œì„ \n  - timestamp, viewer_id, content, session_id í•„ë“œ í¬í•¨\n  - isAction í•„ë“œ ì¶”ê°€ (ë·°ì–´ ì•¡ì…˜ ì—¬ë¶€ í‘œì‹œ)\n  - ì„¸ì…˜ë³„ íƒ€ìž„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ì¸ë±ìŠ¤ ì¶”ê°€\n  - ì‹œì²­ìž ID ê¸°ë°˜ ì¸ë±ìŠ¤ ì¶”ê°€\n  - isAction í•„ë“œ ê¸°ë°˜ ì¸ë±ìŠ¤ ì¶”ê°€\n- [ ] ëŒ€ëŸ‰ ì±„íŒ… ë¡œê·¸ ì €ìž¥ì„ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”\n  - ì„¸ì…˜ ì¢…ë£Œ ì‹œ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì‚½ìž… êµ¬í˜„\n  - íŠ¸ëžœìž­ì…˜ ì²˜ë¦¬ ìµœì í™”\n- [ ] ë·°ì–´ ì•¡ì…˜ ë¡œê·¸ ì €ìž¥ ìµœì í™”\n  - ì¢‹ì•„ìš”, íŒ”ë¡œìš°, ì„ ë¬¼ ë“±ì˜ ì•¡ì…˜ì„ [ì•¡ì…˜+ì„¸ë¶€ë‚´ìš©] í˜•íƒœë¡œ ì €ìž¥\n  - ì•¡ì…˜ ìœ í˜•ë³„ í•„í„°ë§ì„ ìœ„í•œ ì¸ë±ìŠ¤ ë° ì¿¼ë¦¬ ìµœì í™”\n\n### 8. TTS ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ í…Œì´ë¸” ì¶”ê°€\n- [ ] tts_streaming_logs í…Œì´ë¸” ìƒì„±\n  - id, session_id, character_id, response_id, latency, completion_time, error, timestamp í•„ë“œ í¬í•¨\n  - ì„¸ì…˜ë³„, ìºë¦­í„°ë³„ ì¸ë±ìŠ¤ ì¶”ê°€\n  - ì„±ëŠ¥ ë¶„ì„ì„ ìœ„í•œ latency ë° completion_time í•„ë“œ ì¸ë±ìŠ¤ ì¶”ê°€\n- [ ] tts_voice_profiles í…Œì´ë¸” ìƒì„±\n  - id, character_id, elevenlabs_voice_id, settings, created_at, updated_at í•„ë“œ í¬í•¨\n  - ìºë¦­í„°ë³„ ìŒì„± í”„ë¡œí•„ ê´€ë¦¬ë¥¼ ìœ„í•œ êµ¬ì¡° ì„¤ê³„",
        "testStrategy": "1. RLS ì •ì±… í…ŒìŠ¤íŠ¸\n   - ê° ì—­í• ë³„ë¡œ CRUD ìž‘ì—… ì‹œë„ ë° ê¶Œí•œ ê²€ì¦\n   - ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ìžì˜ ì ‘ê·¼ ì°¨ë‹¨ í™•ì¸\n\n2. ì œì•½ ì¡°ê±´ í…ŒìŠ¤íŠ¸\n   - ì™¸ëž˜í‚¤ ìœ„ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n   - NOT NULL ì œì•½ ì¡°ê±´ ìœ„ë°˜ í…ŒìŠ¤íŠ¸\n   - CHECK ì œì•½ ì¡°ê±´ ìœ„ë°˜ í…ŒìŠ¤íŠ¸\n\n3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì¸ë±ìŠ¤ ì ìš© ì „/í›„ ì¿¼ë¦¬ ì„±ëŠ¥ ë¹„êµ\n   - ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œì˜ ì¿¼ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n   \n4. í”„ë¡¬í”„íŠ¸ ë° ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n   - CRUD ìž‘ì—… í…ŒìŠ¤íŠ¸\n   - ë²„ì „ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   - í™œì„±í™”/ë¹„í™œì„±í™” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   \n5. AI ì‘ë‹µ ì €ìž¥ í…ŒìŠ¤íŠ¸\n   - ì‘ë‹µ ì €ìž¥ ë° ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì„¸ì…˜ë³„, ìºë¦­í„°ë³„, íƒœê·¸ë³„ í•„í„°ë§ í…ŒìŠ¤íŠ¸\n   - íƒ€ìž„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ì •ë ¬ ë° ë²”ìœ„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n   - ëŒ€ìš©ëŸ‰ ì‘ë‹µ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   \n6. ì±„íŒ… ë¡œê·¸ ì €ìž¥ í…ŒìŠ¤íŠ¸\n   - ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì±„íŒ… ë¡œê·¸ ì¼ê´„ ì €ìž¥ í…ŒìŠ¤íŠ¸\n   - ëŒ€ìš©ëŸ‰ ì±„íŒ… ë¡œê·¸ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì‹œì²­ìž ID ë° íƒ€ìž„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì„¸ì…˜ë³„ ì±„íŒ… ë¡œê·¸ ê²€ìƒ‰ ë° ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ë·°ì–´ ì•¡ì…˜ ë¡œê·¸ ì €ìž¥ ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n   - [ì•¡ì…˜+ì„¸ë¶€ë‚´ìš©] í˜•ì‹ì˜ ë¡œê·¸ í•„í„°ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì•¡ì…˜ ìœ í˜•ë³„ í†µê³„ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n   \n7. TTS ìŠ¤íŠ¸ë¦¬ë° ë¡œê·¸ í…ŒìŠ¤íŠ¸\n   - ìŠ¤íŠ¸ë¦¬ë° ë¡œê·¸ ì €ìž¥ ë° ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   - ì„±ëŠ¥ ì§€í‘œ(latency, completion_time) ë¶„ì„ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n   - ì„¸ì…˜ë³„, ìºë¦­í„°ë³„ TTS ì„±ëŠ¥ ë¶„ì„ í…ŒìŠ¤íŠ¸\n   - ì˜¤ë¥˜ ë°œìƒ íŒ¨í„´ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n   \n8. TTS ìŒì„± í”„ë¡œí•„ ê´€ë¦¬ í…ŒìŠ¤íŠ¸\n   - ìŒì„± í”„ë¡œí•„ CRUD ìž‘ì—… í…ŒìŠ¤íŠ¸\n   - ìºë¦­í„°ë³„ ìŒì„± í”„ë¡œí•„ ì—°ê²° í…ŒìŠ¤íŠ¸\n   - ìŒì„± ì„¤ì • ì—…ë°ì´íŠ¸ ë° ì ìš© í…ŒìŠ¤íŠ¸",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-06-16T07:28:32.014Z",
      "updated": "2025-06-16T07:28:32.015Z",
      "description": "Tasks for master context"
    }
  }
}